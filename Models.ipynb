{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOwCH6l7/nE8xDojvhmBwEw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# !pip install autogluon"],"metadata":{"id":"olfy_2JZB5_r"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LaQgtdnCBtJ5"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import os\n","from autogluon.tabular import TabularPredictor"]},{"cell_type":"markdown","source":["## RM"],"metadata":{"id":"z5Ra2rNvCLnU"}},{"cell_type":"code","source":["data_rm = pd.read_csv(\"dane-żeliwo-ADI/data_1.csv\")"],"metadata":{"id":"DwYPFDF_-p1w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["label = \"y_RM\""],"metadata":{"id":"sgLfherFDjDW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_rm = TabularPredictor(label=label)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"54zWNXmEDnwF","executionInfo":{"status":"ok","timestamp":1701629146183,"user_tz":-60,"elapsed":253,"user":{"displayName":"Filip Pazio","userId":"05698240051561707055"}},"outputId":"cbdfdb7a-6d16-4e08-a7fc-5203aacaf4f2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["No path specified. Models will be saved in: \"AutogluonModels/ag-20231203_184545\"\n"]}]},{"cell_type":"code","source":["model_rm.fit(data_rm)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gHDyZWyMNsjr","executionInfo":{"status":"ok","timestamp":1701628993230,"user_tz":-60,"elapsed":21746,"user":{"displayName":"Filip Pazio","userId":"05698240051561707055"}},"outputId":"8e95dee0-40b5-456e-83f4-491c9f2e3c2a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n","\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n","\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n","\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n","\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n","\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n","Beginning AutoGluon training ...\n","AutoGluon will save models to \"AutogluonModels/ag-20231203_184250\"\n","=================== System Info ===================\n","AutoGluon Version:  1.0.0\n","Python Version:     3.10.12\n","Operating System:   Linux\n","Platform Machine:   x86_64\n","Platform Version:   #1 SMP Wed Aug 30 11:19:59 UTC 2023\n","CPU Count:          2\n","Memory Avail:       11.13 GB / 12.68 GB (87.8%)\n","Disk Space Avail:   73.62 GB / 107.72 GB (68.3%)\n","===================================================\n","Train Data Rows:    1094\n","Train Data Columns: 27\n","Label Column:       y_RM\n","AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n","\tLabel info (max, min, mean, stddev): (2000.0, 0.0, 1095.29963, 247.87239)\n","\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n","Problem Type:       regression\n","Preprocessing data ...\n","Using Feature Generators to preprocess the data ...\n","Fitting AutoMLPipelineFeatureGenerator...\n","\tAvailable Memory:                    11393.69 MB\n","\tTrain Data (Original)  Memory Usage: 0.23 MB (0.0% of available memory)\n","\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n","\tStage 1 Generators:\n","\t\tFitting AsTypeFeatureGenerator...\n","\tStage 2 Generators:\n","\t\tFitting FillNaFeatureGenerator...\n","\tStage 3 Generators:\n","\t\tFitting IdentityFeatureGenerator...\n","\tStage 4 Generators:\n","\t\tFitting DropUniqueFeatureGenerator...\n","\tStage 5 Generators:\n","\t\tFitting DropDuplicatesFeatureGenerator...\n","\tTypes of features in original data (raw dtype, special dtypes):\n","\t\t('float', []) : 27 | ['C [%]', 'Si [%]', 'S [%]', 'P [%]', 'Mg [%]', ...]\n","\tTypes of features in processed data (raw dtype, special dtypes):\n","\t\t('float', []) : 27 | ['C [%]', 'Si [%]', 'S [%]', 'P [%]', 'Mg [%]', ...]\n","\t0.1s = Fit runtime\n","\t27 features in original data used to generate 27 features in processed data.\n","\tTrain Data (Processed) Memory Usage: 0.23 MB (0.0% of available memory)\n","Data preprocessing and feature engineering runtime = 0.19s ...\n","AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n","\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n","\tTo change this, specify the eval_metric parameter of Predictor()\n","Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 875, Val Rows: 219\n","User-specified model hyperparameters to be fit:\n","{\n","\t'NN_TORCH': {},\n","\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n","\t'CAT': {},\n","\t'XGB': {},\n","\t'FASTAI': {},\n","\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n","\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n","\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n","}\n","Fitting 11 L1 models ...\n","Fitting model: KNeighborsUnif ...\n","\t-219.8017\t = Validation score   (-root_mean_squared_error)\n","\t2.77s\t = Training   runtime\n","\t0.06s\t = Validation runtime\n","Fitting model: KNeighborsDist ...\n","\t-205.0413\t = Validation score   (-root_mean_squared_error)\n","\t0.01s\t = Training   runtime\n","\t0.0s\t = Validation runtime\n","Fitting model: LightGBMXT ...\n","\t-189.5412\t = Validation score   (-root_mean_squared_error)\n","\t1.5s\t = Training   runtime\n","\t0.01s\t = Validation runtime\n","Fitting model: LightGBM ...\n","\t-194.009\t = Validation score   (-root_mean_squared_error)\n","\t0.51s\t = Training   runtime\n","\t0.0s\t = Validation runtime\n","Fitting model: RandomForestMSE ...\n","\t-194.5342\t = Validation score   (-root_mean_squared_error)\n","\t3.75s\t = Training   runtime\n","\t0.08s\t = Validation runtime\n","Fitting model: CatBoost ...\n","\t-191.1671\t = Validation score   (-root_mean_squared_error)\n","\t2.44s\t = Training   runtime\n","\t0.0s\t = Validation runtime\n","Fitting model: ExtraTreesMSE ...\n","\t-193.8457\t = Validation score   (-root_mean_squared_error)\n","\t0.93s\t = Training   runtime\n","\t0.09s\t = Validation runtime\n","Fitting model: NeuralNetFastAI ...\n","\t-191.2491\t = Validation score   (-root_mean_squared_error)\n","\t2.6s\t = Training   runtime\n","\t0.01s\t = Validation runtime\n","Fitting model: XGBoost ...\n","\t-192.0799\t = Validation score   (-root_mean_squared_error)\n","\t0.71s\t = Training   runtime\n","\t0.0s\t = Validation runtime\n","Fitting model: NeuralNetTorch ...\n","\t-211.0654\t = Validation score   (-root_mean_squared_error)\n","\t3.54s\t = Training   runtime\n","\t0.02s\t = Validation runtime\n","Fitting model: LightGBMLarge ...\n","\t-196.3242\t = Validation score   (-root_mean_squared_error)\n","\t1.46s\t = Training   runtime\n","\t0.0s\t = Validation runtime\n","Fitting model: WeightedEnsemble_L2 ...\n","\tEnsemble Weights: {'LightGBMXT': 0.638, 'NeuralNetFastAI': 0.362}\n","\t-188.7263\t = Validation score   (-root_mean_squared_error)\n","\t0.43s\t = Training   runtime\n","\t0.0s\t = Validation runtime\n","AutoGluon training complete, total runtime = 21.48s ... Best model: \"WeightedEnsemble_L2\"\n","TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231203_184250\")\n"]},{"output_type":"execute_result","data":{"text/plain":["<autogluon.tabular.predictor.predictor.TabularPredictor at 0x7a07fb75c340>"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","source":["# Martensite volume"],"metadata":{"id":"Y7uAoLskCGGr"}},{"cell_type":"code","source":["data_m = pd.read_csv(\"dane-żeliwo-ADI/data_2.csv\")"],"metadata":{"id":"YCYPy38qPegv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["label = \"y_MV\""],"metadata":{"id":"cNHoXmUv_6Cj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_mv = TabularPredictor(label=label)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J_Eb8ndKAD7g","executionInfo":{"status":"ok","timestamp":1701629198406,"user_tz":-60,"elapsed":235,"user":{"displayName":"Filip Pazio","userId":"05698240051561707055"}},"outputId":"1bb0ecb9-a3f2-4d33-bdc3-3e78f31fc986"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["No path specified. Models will be saved in: \"AutogluonModels/ag-20231203_184637\"\n"]}]},{"cell_type":"code","source":["model_mv.fit(data_m)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w0GiypguAFpK","executionInfo":{"status":"ok","timestamp":1701629219516,"user_tz":-60,"elapsed":7979,"user":{"displayName":"Filip Pazio","userId":"05698240051561707055"}},"outputId":"fbcbd74c-2b60-4dbb-f01e-4615dc4e065f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n","\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n","\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n","\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n","\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n","\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n","Beginning AutoGluon training ...\n","AutoGluon will save models to \"AutogluonModels/ag-20231203_184637\"\n","=================== System Info ===================\n","AutoGluon Version:  1.0.0\n","Python Version:     3.10.12\n","Operating System:   Linux\n","Platform Machine:   x86_64\n","Platform Version:   #1 SMP Wed Aug 30 11:19:59 UTC 2023\n","CPU Count:          2\n","Memory Avail:       10.92 GB / 12.68 GB (86.1%)\n","Disk Space Avail:   73.60 GB / 107.72 GB (68.3%)\n","===================================================\n","Train Data Rows:    49\n","Train Data Columns: 27\n","Label Column:       y_MV\n","AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n","\tLabel info (max, min, mean, stddev): (64.0, 0.0, 12.71843, 17.22656)\n","\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n","Problem Type:       regression\n","Preprocessing data ...\n","Using Feature Generators to preprocess the data ...\n","Fitting AutoMLPipelineFeatureGenerator...\n","\tAvailable Memory:                    11182.12 MB\n","\tTrain Data (Original)  Memory Usage: 0.01 MB (0.0% of available memory)\n","\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n","\tStage 1 Generators:\n","\t\tFitting AsTypeFeatureGenerator...\n","\t\t\tNote: Converting 5 features to boolean dtype as they only contain 2 unique values.\n","\tStage 2 Generators:\n","\t\tFitting FillNaFeatureGenerator...\n","\tStage 3 Generators:\n","\t\tFitting IdentityFeatureGenerator...\n","\tStage 4 Generators:\n","\t\tFitting DropUniqueFeatureGenerator...\n","\tStage 5 Generators:\n","\t\tFitting DropDuplicatesFeatureGenerator...\n","\tUseless Original Features (Count: 2): ['Austenitization time [min.]', 'Isothermal process time [min.]']\n","\t\tThese features carry no predictive signal and should be manually investigated.\n","\t\tThis is typically a feature which has the same value for all rows.\n","\t\tThese features do not need to be present at inference time.\n","\tUnused Original Features (Count: 5): ['Sn [%]', 'B [%]', 'V [%]', 'Austenitization temp [C]', 'Isothermal process temp [C]']\n","\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n","\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n","\t\tThese features do not need to be present at inference time.\n","\t\t('float', []) : 5 | ['Sn [%]', 'B [%]', 'V [%]', 'Austenitization temp [C]', 'Isothermal process temp [C]']\n","\tTypes of features in original data (raw dtype, special dtypes):\n","\t\t('float', []) : 20 | ['C [%]', 'Si [%]', 'S [%]', 'P [%]', 'Mg [%]', ...]\n","\tTypes of features in processed data (raw dtype, special dtypes):\n","\t\t('float', [])     : 19 | ['C [%]', 'Si [%]', 'S [%]', 'P [%]', 'Mg [%]', ...]\n","\t\t('int', ['bool']) :  1 | ['Al [%]']\n","\t0.2s = Fit runtime\n","\t20 features in original data used to generate 20 features in processed data.\n","\tTrain Data (Processed) Memory Usage: 0.01 MB (0.0% of available memory)\n","Data preprocessing and feature engineering runtime = 0.25s ...\n","AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n","\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n","\tTo change this, specify the eval_metric parameter of Predictor()\n","Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 39, Val Rows: 10\n","User-specified model hyperparameters to be fit:\n","{\n","\t'NN_TORCH': {},\n","\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n","\t'CAT': {},\n","\t'XGB': {},\n","\t'FASTAI': {},\n","\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n","\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n","\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n","}\n","Fitting 11 L1 models ...\n","Fitting model: KNeighborsUnif ...\n","\t-13.0604\t = Validation score   (-root_mean_squared_error)\n","\t0.02s\t = Training   runtime\n","\t0.0s\t = Validation runtime\n","Fitting model: KNeighborsDist ...\n","\t-14.711\t = Validation score   (-root_mean_squared_error)\n","\t0.01s\t = Training   runtime\n","\t0.0s\t = Validation runtime\n","Fitting model: LightGBMXT ...\n","\t-13.5415\t = Validation score   (-root_mean_squared_error)\n","\t0.38s\t = Training   runtime\n","\t0.0s\t = Validation runtime\n","Fitting model: LightGBM ...\n","\t-13.5415\t = Validation score   (-root_mean_squared_error)\n","\t0.34s\t = Training   runtime\n","\t0.0s\t = Validation runtime\n","Fitting model: RandomForestMSE ...\n","\t-14.2881\t = Validation score   (-root_mean_squared_error)\n","\t1.05s\t = Training   runtime\n","\t0.17s\t = Validation runtime\n","Fitting model: CatBoost ...\n","\t-13.1903\t = Validation score   (-root_mean_squared_error)\n","\t0.47s\t = Training   runtime\n","\t0.0s\t = Validation runtime\n","Fitting model: ExtraTreesMSE ...\n","\t-14.3031\t = Validation score   (-root_mean_squared_error)\n","\t1.09s\t = Training   runtime\n","\t0.09s\t = Validation runtime\n","Fitting model: NeuralNetFastAI ...\n","\t-12.8695\t = Validation score   (-root_mean_squared_error)\n","\t1.63s\t = Training   runtime\n","\t0.01s\t = Validation runtime\n","Fitting model: XGBoost ...\n","\t-13.2476\t = Validation score   (-root_mean_squared_error)\n","\t0.14s\t = Training   runtime\n","\t0.0s\t = Validation runtime\n","Fitting model: NeuralNetTorch ...\n","\t-12.9995\t = Validation score   (-root_mean_squared_error)\n","\t0.56s\t = Training   runtime\n","\t0.02s\t = Validation runtime\n","Fitting model: LightGBMLarge ...\n","\t-13.1633\t = Validation score   (-root_mean_squared_error)\n","\t0.38s\t = Training   runtime\n","\t0.0s\t = Validation runtime\n","Fitting model: WeightedEnsemble_L2 ...\n","\tEnsemble Weights: {'NeuralNetFastAI': 0.53, 'NeuralNetTorch': 0.47}\n","\t-12.3767\t = Validation score   (-root_mean_squared_error)\n","\t0.56s\t = Training   runtime\n","\t0.0s\t = Validation runtime\n","AutoGluon training complete, total runtime = 7.53s ... Best model: \"WeightedEnsemble_L2\"\n","TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231203_184637\")\n"]},{"output_type":"execute_result","data":{"text/plain":["<autogluon.tabular.predictor.predictor.TabularPredictor at 0x7a07224dd510>"]},"metadata":{},"execution_count":28}]}]}